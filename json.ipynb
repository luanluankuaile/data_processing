{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4acfe838-1aca-41be-83a6-3a75cf4d32b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               docId|\n",
      "+--------------------+\n",
      "|[IEEVuN4hn_RpPLBr...|\n",
      "|                  []|\n",
      "|[3ht5gRc6_jkQqVFz...|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|   [[object Object]]|\n",
      "|[uft-MEw__ulWSczY...|\n",
      "|                NULL|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basicInfo json\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, StringType, MapType,ArrayType,DateType,IntegerType,BooleanType\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df=spark.read.option(\"escape\", \"\\\"\").csv('data/basic_info.csv',header='true')\n",
    "df_personal=df.where(\"module=='basicInfo'\")\n",
    "\n",
    "basic_Info_schema= StructType([\n",
    "    StructField(\"status\",  StringType(),nullable=True),\n",
    "    StructField(\"surNameEng\", StringType(),nullable=True),\n",
    "    StructField(\"otherNameEng\", StringType(),nullable=True),\n",
    "    StructField(\"formerSurNameEng\", StringType(),nullable=True),\n",
    "    StructField(\"formerOtherNameEng\", StringType(),nullable=True),\n",
    "    StructField(\"fullNameChi\", StringType(),nullable=True),\n",
    "    StructField(\"formerFullNameChi\", StringType(),nullable=True),\n",
    "    StructField(\"aliasEng\", StringType(),nullable=True),\n",
    "    StructField(\"nameChangeCertificate\", MapType(StringType(),ArrayType(StringType())),nullable=True),\n",
    "    StructField(\"gender\", StringType(),nullable=True),\n",
    "    StructField(\"dateOfBirth\", StringType(),nullable=True),  # 注意，这里我也用字符串类型，你可能需要根据数据调整为DateType()\n",
    "    StructField(\"nationality\", IntegerType(),nullable=True),\n",
    "    StructField(\"placeOfBirth\", StringType(),nullable=True),\n",
    "    StructField(\"bizAttirePhoto\", MapType(StringType(),ArrayType(StringType())),nullable=True),\n",
    "    StructField(\"idNumber\", StringType(),nullable=True),\n",
    "    StructField(\"chCommercialCode\", StringType(),nullable=True),\n",
    "    StructField(\"idCard\", MapType(StringType(),ArrayType(StringType())),nullable=True),\n",
    "    StructField(\"isHongKongResident\", StringType(),nullable=True),\n",
    "    StructField(\"passport\", MapType(StringType(),ArrayType(StringType())),nullable=True),\n",
    "    StructField(\"employmentVisa\", MapType(StringType(),ArrayType(StringType())),nullable=True),\n",
    "    StructField(\"email\", StringType(),nullable=True),\n",
    "    StructField(\"mobilePhoneNo\", StringType(),nullable=True),\n",
    "    StructField(\"mobilePhoneNoPrefix\", StringType(),nullable=True),\n",
    "    StructField(\"daytimeContactNo\", StringType(),nullable=True),\n",
    "    StructField(\"daytimeContactNoPrefix\", StringType(),nullable=True),\n",
    "    StructField(\"addrFlatRoom\", StringType(),nullable=True),\n",
    "    StructField(\"addrBuildingName\", StringType(),nullable=True),\n",
    "    StructField(\"addrStreetNumber\", StringType(),nullable=True),\n",
    "    StructField(\"area\", StringType(),nullable=True),\n",
    "    StructField(\"bizAddr\", StringType(),nullable=True)\n",
    "])\n",
    "content_schema = StructType([\n",
    "    StructField(\"personalInfo\", basic_Info_schema)\n",
    "])\n",
    "\n",
    "df_personal = df_personal.withColumn(\"parsed\", from_json(\"content\", content_schema))\n",
    "df_personal.select(\"parsed.personalInfo.nameChangeCertificate.docId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c843426-308e-462c-8843-3ed83bc26775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------+\n",
      "|status|heldAgentContractLifeInsurance|\n",
      "+------+------------------------------+\n",
      "| saved|                            no|\n",
      "|  NULL|                            no|\n",
      "| saved|                           yes|\n",
      "+------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generalDisclosure json\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, StringType, MapType,ArrayType,DateType,IntegerType,BooleanType\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df=spark.read.option(\"escape\", \"\\\"\").csv('data/general_disclosure.csv',header='true')\n",
    "df_general=df.where(\"module=='generalDisclosure'\")\n",
    "\n",
    "generalLicenses_schema = StructType([\n",
    "    StructField(\"status\", StringType(), nullable=True),\n",
    "    StructField(\"heldAgentContractLifeInsurance\", StringType(), nullable=True),\n",
    "    StructField(\"annualIncomeAbove360k\", StringType(), nullable=True),\n",
    "    StructField(\"heldBusinessOrManagementPosition\", StringType(), nullable=True),\n",
    "    StructField(\"relativeWorkingInFTLife\", StringType(), nullable=True),\n",
    "    StructField(\"relativeWorkingInFTLifeName\", StringType(), nullable=True),\n",
    "    StructField(\"relativeWorkingInFTLifeCorpName\", StringType(), nullable=True),\n",
    "    StructField(\"directorShareholderController\", StringType(), nullable=True),\n",
    "    StructField(\"generalAndLicenseGeneralQ5Particulars\", StringType(), nullable=True),\n",
    "    StructField(\"relativeOfFTLife\", StringType(), nullable=True),\n",
    "    StructField(\"relativeOfFTLifeParticulars\", StringType(), nullable=True),\n",
    "    StructField(\"registeredWithMPFA\", StringType(), nullable=True),\n",
    "    StructField(\"registeredWithMPFAMPF\", StringType(), nullable=True),\n",
    "    StructField(\"licencedBySFC\", StringType(), nullable=True),\n",
    "    StructField(\"registeredWithHKMA\", StringType(), nullable=True),\n",
    "    StructField(\"registeredWithHKMAHKMA\", StringType(), nullable=True),\n",
    "    StructField(\"licencedByOtherRegulators\", StringType(), nullable=True),\n",
    "    StructField(\"licencedByOtherRegulatorsName\", StringType(), nullable=True),\n",
    "    StructField(\"licencedByOtherRegulatorsRegistration\", StringType(), nullable=True),\n",
    "    StructField(\"s1Upload\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "content_schema = StructType([\n",
    "    StructField(\"generalLicenses\", generalLicenses_schema),\n",
    "])\n",
    "\n",
    "# 然后对DataFrame应用\n",
    "df_general = df_general.withColumn(\"parsed\", from_json(\"content\", content_schema))\n",
    "\n",
    "# 举例访问解析后的字段\n",
    "df_general.select(\"parsed.generalLicenses.status\", \"parsed.generalLicenses.heldAgentContractLifeInsurance\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "881bede7-c905-4d70-8a32-e142301eb3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|         state|         state|\n",
      "+--------------+--------------+\n",
      "|          PASS|NOT_APPLICABLE|\n",
      "|          PASS|       DEFAULT|\n",
      "|          PASS|NOT_APPLICABLE|\n",
      "|NOT_APPLICABLE|       DEFAULT|\n",
      "|          PASS|        EXEMPT|\n",
      "|          PASS|          PASS|\n",
      "|          PASS| GRANDFATHERED|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iiqe json\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, StringType, MapType,ArrayType,DateType,IntegerType,BooleanType\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df=spark.read.option(\"escape\", \"\\\"\").csv('data/iiqe.csv',header='true')\n",
    "df_iiqe=df.where(\"module=='iiqe'\")\n",
    "\n",
    "doc_schema = StructType([\n",
    "    StructField(\"createBy\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"fileName\", StringType(), True),\n",
    "    StructField(\"createTime\", StringType(), True)  # 注意：这里我使用 StringType 来处理日期类型，你可能需要根据你的需求使用其他类型。\n",
    "])\n",
    "\n",
    "paper_schema = StructType([\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"doc\", doc_schema, True)\n",
    "])\n",
    "\n",
    "papers_schema = StructType([\n",
    "    StructField(\"paper1\", paper_schema, True),\n",
    "    StructField(\"paper2\", paper_schema, True),\n",
    "    StructField(\"paper3\", paper_schema, True),\n",
    "    StructField(\"paper4\", paper_schema, True),\n",
    "    StructField(\"paper5\", paper_schema, True),\n",
    "])\n",
    "\n",
    "content_schema = StructType([\n",
    "    StructField(\"papers\", papers_schema)\n",
    "])\n",
    "\n",
    "# 在你的 DataFrame 中应用这个 schema\n",
    "df_iiqe = df_iiqe.withColumn(\"parsed\", from_json(df.content, content_schema))\n",
    "\n",
    "# 访问解析后的字段\n",
    "df_iiqe.select(\"parsed.papers.paper1.state\", \"parsed.papers.paper2.state\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb438468-34d6-4755-a9a3-5899a8ee9d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                  id|              module|             content|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|01hzcptwwr3xrgz19...|supplementalDocum...|{\"status\":\"saved\"...|\n",
      "|01hzedpt8y7tvf0k7...|supplementalDocum...|{\"status\":\"saved\"...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n",
      "+-------------+--------------------+-----------------------------+\n",
      "|parsed.status|parsed.accountNumber|parsed.accountStatement.docId|\n",
      "+-------------+--------------------+-----------------------------+\n",
      "|        saved|      12345678901234|            [[object Object]]|\n",
      "|        saved|          1234567890|         [h7TVQ38fC__9MuVm...|\n",
      "+-------------+--------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#supplementalDocuments json\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, StringType, MapType,ArrayType,DateType,IntegerType,BooleanType\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df=spark.read.option(\"escape\", \"\\\"\").csv('data/supplemental_documents.csv',header='true')\n",
    "df_supplemental=df.where(\"module=='supplementalDocuments'\")\n",
    "df_supplemental.show()\n",
    "\n",
    "docId_schema = StructType([\n",
    "    StructField(\"docId\", ArrayType(StringType(), True), True)\n",
    "])\n",
    "\n",
    "main_schema = StructType([\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"accountNumber\", StringType(), True),\n",
    "    StructField(\"accountStatement\", docId_schema, True),\n",
    "    StructField(\"incomeProof\", docId_schema, True),\n",
    "    StructField(\"iaLicense\", docId_schema, True), \n",
    "    StructField(\"continueProfessional\", docId_schema, True),\n",
    "    StructField(\"licenseRevocation\", docId_schema, True)\n",
    "])\n",
    "\n",
    "# 在DataFrame中应用这个schema\n",
    "df_supplemental = df_supplemental.withColumn(\"parsed\", from_json(df.content, main_schema))\n",
    "\n",
    "# 访问解析后的字段\n",
    "df_supplemental.select(df_supplemental.parsed.status, df_supplemental.parsed.accountNumber, df_supplemental.parsed.accountStatement.docId).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "65b6ba01-ffe4-45e7-8dd1-a8a572cf2ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|parsed                                                                                                                                                                                                                        |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[]                                                                                                                                                                                                                            |\n",
      "|[{query, Prospect}, {read, Prospect}, {download, Prospect}]                                                                                                                                                                   |\n",
      "|[{query, Prospect}, {read, Prospect}, {download, Prospect}, {query, Application}, {read, Application}]                                                                                                                        |\n",
      "|[{query, Prospect}, {read, Prospect}, {download, Prospect}, {query, Application}, {read, Application}]                                                                                                                        |\n",
      "|[{query, Prospect}, {read, Prospect}, {download, Prospect}, {query, Application}, {read, Application}, {update, Prospect}]                                                                                                    |\n",
      "|[{query, Prospect}, {read, Prospect}, {download, Prospect}, {query, Application}, {read, Application}]                                                                                                                        |\n",
      "|[{download, Prospect}, {query, Application}, {download, Application}, {read, Application}, {assign, Application}, {verify, Application}, {procceed, Application}, {update, DueDiligence}, {download, XML}, {update, Prospect}]|\n",
      "|[{download, Prospect}, {assign, Application}, {verify, Application}, {update, DueDiligence}, {procceed, Application}, {download, XML}, {update, Prospect}]                                                                    |\n",
      "|[{download, Prospect}, {query, Application}, {download, Application}, {download, IA}, {read, Application}, {verify, Application}, {update, DueDiligence}, {procceed, Application}, {download, XML}, {update, Prospect}]       |\n",
      "|[{invite, Prospect}, {query, Prospect}, {read, Prospect}, {download, Prospect}, {query, Application}, {read, Application}, {update, Prospect}]                                                                                |\n",
      "|[{create, Prospect}, {invite, Prospect}, {update, Prospect}, {query, Prospect}, {read, Prospect}, {download, Prospect}, {query, Application}, {read, Application}, {update, Prospect}]                                        |\n",
      "|[{query, Prospect}, {download, Prospect}]                                                                                                                                                                                     |\n",
      "|[{create, Prospect}, {invite, Prospect}, {query, Prospect}, {read, Prospect}, {download, Prospect}, {query, Application}, {read, Application}]                                                                                |\n",
      "|[{query, Prospect}]                                                                                                                                                                                                           |\n",
      "|[{create, Prospect}, {invite, Prospect}, {query, Prospect}, {read, Prospect}, {create, Application}, {download, Prospect}, {query, Application}, {read, Application}, {update, Application}, {read, CertTrueCopy}]            |\n",
      "|[{read, User}, {read, Prospect}, {update, Prospect}, {create, Application}, {update, Application}, {submit, Application}, {read, CertTrueCopy}, {read, Contract}, {sign, Contract}]                                           |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, StringType, MapType,ArrayType,DateType,IntegerType,BooleanType\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df=spark.read.option(\"escape\", \"\\\"\").csv('data/roles.csv',header='true')\n",
    "\n",
    "main_schema = ArrayType(StructType([\n",
    "    StructField(\"action\", StringType(), nullable=True),\n",
    "    StructField(\"subject\", StringType(), nullable=True)\n",
    "]))\n",
    "\n",
    "df = df.withColumn(\"parsed\", from_json(df.permissions, main_schema))\n",
    "df.select(df.parsed).show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5bb96-82aa-496e-9e9f-cdb9daf4bc13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
